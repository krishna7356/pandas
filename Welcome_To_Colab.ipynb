{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna7356/pandas/blob/gen-AI/Welcome_To_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = [\n",
        "    # Review 1: Positive\n",
        "    \"I absolutely love the new QuantumX Pro camera! The picture quality is stellar and the battery life is amazing. Shipped super fast too. A++!\",\n",
        "\n",
        "    # Review 2: Negative with specific issue\n",
        "    \"The SonicWave earbuds have a serious design flaw. The left earbud stopped charging after just one week. I expected better for the price. Very disappointed.\",\n",
        "\n",
        "    # Review 3: Mixed with a question\n",
        "    \"The Titan smartwatch is decent. The screen is bright and the features are good, but the step counter seems inaccurate. It's off by at least 20%. Is there a way to calibrate it?\",\n",
        "\n",
        "    # Review 4: Negative with multiple issues\n",
        "    \"My order for the AeroDrone was a disaster. It arrived with a broken propeller and the battery was completely dead on arrival. Customer service has been unresponsive for 3 days.\",\n",
        "\n",
        "    # Review 5: Positive but mentions a minor issue\n",
        "    \"Overall, I'm happy with the PureGlow Air Purifier. It's quiet and effective. My only complaint is that the replacement filters are a bit expensive.\"\n",
        "]"
      ],
      "metadata": {
        "id": "_vxgNNWy2EOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load GPT-2 tokenizer\n",
        "gpt2_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Load BERT-base-uncased tokenizer\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Example usage\n",
        "text = \"Hello, how are you?\"\n",
        "\n",
        "print(\"GPT-2 Tokenized:\", gpt2_tokenizer.tokenize(reviews[3]))\n",
        "print(\"BERT Tokenized:\", bert_tokenizer.tokenize(reviews[3]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEjGft8yGXK6",
        "outputId": "64d4b543-8119-4aeb-804c-0fbea3258239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-2 Tokenized: ['My', 'Ġorder', 'Ġfor', 'Ġthe', 'ĠAero', 'Dr', 'one', 'Ġwas', 'Ġa', 'Ġdisaster', '.', 'ĠIt', 'Ġarrived', 'Ġwith', 'Ġa', 'Ġbroken', 'Ġprope', 'ller', 'Ġand', 'Ġthe', 'Ġbattery', 'Ġwas', 'Ġcompletely', 'Ġdead', 'Ġon', 'Ġarrival', '.', 'ĠCustomer', 'Ġservice', 'Ġhas', 'Ġbeen', 'Ġun', 'responsive', 'Ġfor', 'Ġ3', 'Ġdays', '.']\n",
            "BERT Tokenized: ['my', 'order', 'for', 'the', 'aero', '##dron', '##e', 'was', 'a', 'disaster', '.', 'it', 'arrived', 'with', 'a', 'broken', 'propeller', 'and', 'the', 'battery', 'was', 'completely', 'dead', 'on', 'arrival', '.', 'customer', 'service', 'has', 'been', 'un', '##res', '##pon', '##sive', 'for', '3', 'days', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "# Choose a FLAN-T5 variant (e.g., base, large, xl)\n",
        "model_name = \"google/flan-t5-base\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Example input text (instruction or prompt)\n",
        "input_text = \"Translate English to French: The weather is nice today.\"\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "# Generate output tokens\n",
        "outputs = model.generate(**inputs)\n",
        "\n",
        "# Decode generated tokens\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Output:\", result)\n"
      ],
      "metadata": {
        "id": "-dlu7OWfHGaO",
        "outputId": "b7889ac2-5324-4ac2-f1a8-ebf599bfc1e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: La météo est d'ici à l'heure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eYnmX7Bg7cAx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}